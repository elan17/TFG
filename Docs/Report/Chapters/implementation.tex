\chapter{Implementation}
  This chapter introduces some specifications of the implementation
  of our solution.\\


  \section{General autocorrelation function}
    The autocorrelation function introduced in Equation \eqref{eq:4} can be
    implemented in several ways:

      \subsection{Naive approach}
        The naive approach for the autocorrelation function consists in
        computing all the displacements of the sequence and then
        their correlation with the base sequence as shown in Figure
        \ref{naive_auto:fig:1}. Even though this algorythm it's simple and
        follows the mathematical definition, is too slow. The correlation function
        for each component have to be computed, leading to a
        complexity of $O(n^{2})$ (where $n$ is the size of the sequence) with a
        huge constant as building the shifted sequence for each
        component is needed.\\

        This constant can be improved if building the shifts (just
        using slices of the array) is avoided, but the complexity would stay the
        same.

      \subsection{Circular convolution theorem}
        The other option is to step in the world of mathematical properties.
        Fortunatly, there exists the convolution theorem\cite{golomb_ref} that
        lets us express the autocorrelation function in terms of Fourier
        Transforms as:
        \begin{theorem}
          Given a sequence $S$ and the Discrete Fourier Transform($DFT$):
          \begin{equation}
            A(S) = DFT^{-1}[DFT\{S\} Â· DFT\{S\}^{*}]
          \end{equation}
          where $DFT\{S\}^{*}$ represents the complex conjugate of $DFT\{S\}$.
        \end{theorem}

        Notice that, using the Fast Fourier
        Transform\cite{fast_fourier_transform}, the complexity of this
        method lowers to $O(N log N)$. However, its constant is
        still high as applying 2 FFT to the sequence and apply the
        complex conjugate is needed. In fact, keep in mind that Fourier
        Transforms works with complex components while the naive approach keeps
        using the same type as the components which makes its constant even higher
        than the optimized naive approach.

          \begin{figure}
            \inputpython{Chapters/Implementation/naive.py}{0}{100}
            \caption{An example implementation of the naive autocorrelation}
            \label{naive_auto:fig:1}
          \end{figure}

      \subsection{Specific solution for the composition method}

      If a general method for this computation were used, the one based on the
      convolution theorem would be preferred because the program is
      expected to deal with long sequences that will compensate the big constant
      of this method.\\

      However, the sequences this program is dealing with has the special property
      of having been built through the composition method. This means that a non
      general way of computing this autocorrelation with better
      computational characteristics exploting the pecularities of this
      construction might exist.\\

      Taking advantage of Property \ref{composition:prop:1},an algorythm with
      interesting properties can be designed. First of all, the complexity
      function depends on the size of the shift sequence. Being $m$ the
      length of the shift sequence and $n$ the length of the composite
      sequence, the resulting algortyhm has a complexity of $O(nm)$. This means
      that when $m < log(n)$ this algorythm has a better complexity than the
      Fourier Transform's approach.\\

      In addition, this algorythm has a better constant. It only needs to
      iterate once through the autocorrelation sequence. This method is more
      cache friendly too as the data source of the function is smaller and it
      doesn't need to use complex operations in binary sequences.\\

      But the biggest improvement in respect of the Fourier Transform is that
      the complexity of a partial result of size $p$ is $O(mp)$ while the
      convolution theorem requires $O(nlog(n))$ for a partial result. In
      practice this means that, if just checking a certain component
      of the autocorrelation is needed, there is no need to compute the whole
      function.\\

      An example implementation of this algorythm is shown in Figure
      \ref{composite_auto:fig:1}.

      \begin{figure}[ht!]
        \inputpython{Chapters/Implementation/composite.py}{0}{100}
        \caption{The Cython implementation of the composite autocorrelation.
        Notice that branchless programming is used to improve performance.}
        \label{composite_auto:fig:1}
      \end{figure}

  \section{Single-threaded Branch and Bound}

  The theoretical approach for the Branch and Bound algorithm has been already
  explained. In this section, just the actual implementation that was used
  in the project is shown in Figure \ref{composite_auto:fig:2}.

  \begin{figure}[ht!]
    \inputpython{Chapters/Implementation/branch_and_bound.py}{0}{100}
    \caption{A Cython implementation of the branch and bound algorythm. Notice
    the amount of extra code to achive C performance.}
    \label{composite_auto:fig:2}
  \end{figure}


  \section{Parallelism model}

  For the parallelism of the project, it was decided to work with MPI. This model
  was implemented in pure Python as there was no need for a high performance in
  this part of the software (as the time spent in this code is already
  minimal).\\

  However, a low latency assignation of tasks is needed. If shared
  memory was used, every node would need to access memory through the "slow"
  interconnection network. Instead, with MPI, proccesses to talk between them.\\

  For the purpose of this project, MPICH\cite{mpich} is used as the bindings of
  MPI4PY support it and it's the implementation of the cluster we are working
  with\cite{calderon}.\\

  In our particular problem, a set of tasks was defined to
  distribute between the different nodes. This tasks are subtrees from the
  search space with a given height that defines the size of the task. An
  example is show in Figure \ref{tasks:fig:1}. Notice that the tasks are
  completly unbalanced so a static scheduler wouldn't be efficient at all.\\


  \begin{figure}[ht!]
    \begin{center}
      \includegraphics[scale=0.4]{Chapters/Implementation/Example_tasks.png}
    \end{center}
    \caption{An example distribution of tasks for the example at Figure
    \ref{bb:fig:1}.}
    \label{tasks:fig:1}
  \end{figure}

  This model is a good first version. However, if a prune isn't performed when
  assigning the tasks, there will still be an exponential number of tasks
  (specifically, $n^{l-t}$ where $n$ is the length of the base sequence, $l$ the
  length of the shift sequence and $t$ the task size). This shouldn't be a problem
  if $t$ is close to $l$, but this will raise an issue with the task balancer as
  there wouldn't be enough tasks to balance the load.\\

  A second version of the algorithm applies the branch and bound algorythm in
  the master proccess to generate only tasks with good Hamming properties.
  This rules out all tasks that would instantly result in a bad
  autocorrelation and wouldn't generate any useful sequences. The code
  implementation is shown in Figures \ref{parallelism_example:fig:1} and
  \ref{parallelism_example:fig:2}.\\

  \begin{figure}[ht!]
    \inputpython{Chapters/Implementation/Example_parallelism_master.py}{0}{100}
    \caption{A Python implementation of the master proccess}
    \label{parallelism_example:fig:1}
  \end{figure}

  \begin{figure}[ht!]
    \inputpython{Chapters/Implementation/Example_parallelism_slave.py}{0}{100}
    \caption{A Python implementation of an slave proccess}
    \label{parallelism_example:fig:2}
  \end{figure}

  A third version (which wasn't implemented because the second version was
  enough for our objectives) could be done by using the Hamming as an
  heuristic to determine the size of the task. Instead of using a fixed size
  for the subtrees, the tasks to can be given to the process at hand based on the
  Hamming autocorrelation of the root of the task.\\

  \section{UI implementation}

  Last but not least, the design of the User Interface will be briefly discussed.
  As expressed in the chapter of Sofware Engineering, our primary focus is
  its compatibility with command lines. For that, a POSIX compatible
  interface was created.\\

  First, a --help option was developed to list all the flags:
  \begin{lstlisting}
    $ python main.py --help
    usage: python main.py [option...]

    Options and arguments:
    -n : number of threads to use(must be compatible with your MPI enviroment)
         Defaults to the MPI configuration default

    -p : delay between polls in the master thread(higher values will make the
         slaves to wait more until the next task, lower values will increase
         CPU usage of master)

    -s : length of the base sequence(in this version must be a prime number to
         generate Legendre sequences. Other values have undefined behaviour)

    -l : length of shift sequences(this option must be coprime with value
         of s, other values have undefined behaviour)

    -t : size of the task for each thread(this option must be lower than the
         value provided by -l, other values have undefined behaviour)

    -h : maximum hamming autocorrelation allowed(this option must be a
         positive integer other values have undefined behaviour) Defaults to -l

    -c : maximum autocorrelation we are interested in(this option must be a
         positive integer other values have undefined behaviour) Defaults to
         the square root of (-l*-s)

    -v : verbose mode
  \end{lstlisting}

  Verbose mode logs which tasks have been assigned and at which time stamp, as
  well as logging the end of slave proccesses and the idle time of slaves:

  \begin{lstlisting}
    $ python main.py -s 5 -l 23 -t 20 -c 7 -h 3 -v
    2020-08-23 19:27:49 [1] : TASK_ASSIGNED [0, 0, 1] 9ms
    2020-08-23 19:27:49 [3] : TASK_ASSIGNED [0, 0, 3] 10ms
    2020-08-23 19:27:49 [5] : TASK_ASSIGNED [0, 0, 5] 6ms
    2020-08-23 19:27:49 [7] : TASK_ASSIGNED [0, 1, 1] 17ms
    2020-08-23 19:27:49 [6] : TASK_ASSIGNED [0, 1, 0] 3ms
    2020-08-23 19:27:49 [2] : TASK_ASSIGNED [0, 0, 2] 0ms
                            .
                            .
                            .
    2020-08-23 19:28:41 [1] : TASK_ASSIGNED [0, 5, 0] 0ms
    2020-08-23 19:28:42 [7] : TASK_ASSIGNED [0, 5, 3] 0ms
    2020-08-23 19:28:45 [1] : EXITED
    2020-08-23 19:28:45 [5] : TASK_ASSIGNED [0, 5, 2] 0ms
    2020-08-23 19:28:47 [2] : EXITED
    2020-08-23 19:28:48 [4] : TASK_ASSIGNED [0, 5, 4] 0ms
    2020-08-23 19:28:49 [6] : EXITED
    2020-08-23 19:28:52 [3] : EXITED
    2020-08-23 19:28:55 [5] : EXITED
    2020-08-23 19:28:56 [7] : EXITED
    2020-08-23 19:28:57 [4] : EXITED

  \end{lstlisting}

  Notice that, as stdout is used, the log can be piped to a file. The
  output format is designed in a way that eases the use of utilities such as
  awk to proccess the data of the program (one word message, well defined
  columns, etc.).\\

  Verbosity is completly optional and doesn't impact performance when inactive.
  It's particularly useful when tweaking the parameters to get the best
  configuration.\\
  
